{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "![\"One does not simply test in production\"](https://www.flagship.io/wp-content/uploads/meme-one-does-not-simply-test-in-production-768x453.jpg)\n",
        "\n",
        "\n",
        "*This notebook is just for learning some key concepts about testing with python from a data scientist perspective.*\n",
        "\n",
        "*In fact, there are some cools talks available on the Internet*. See resources section at the bottom.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d80Qm8ssCxBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries for testing in Python."
      ],
      "metadata": {
        "id": "Ge5ZGct_iJq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are all of the testing libraries we are going to use in this notebook."
      ],
      "metadata": {
        "id": "xldfMPrnZLTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install engarde\n",
        "!pip -q install pytest\n",
        "!pip -q install hypothesis\n",
        "!pip -q install bulwark\n",
        "!pip -q install pytest-mock"
      ],
      "metadata": {
        "id": "q_welKllETkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460c0c17-cc6c-45ee-c7a0-24f378002633"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/317.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are other libraries we are going to use but they are not for testing."
      ],
      "metadata": {
        "id": "C_dn74tzZQRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w8LHy1bduz2",
        "outputId": "c1df75df-f64d-4a63-a8c0-7db43937b5b4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyspark\n",
        "import time\n",
        "import requests\n",
        "import sqlite3"
      ],
      "metadata": {
        "id": "88jzHZpfUiFD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>Introduction</font>\n",
        "\n",
        "Learning to write good tests is an investment, you gain the benefit over time. "
      ],
      "metadata": {
        "id": "Csx1UAd2mS2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Why test?\n",
        "* Best way we know to figure out the code works.\n",
        "* Testing helps you find bugs earlier.\n",
        "* Well-tested helps you iterate faster.\n",
        "* Well-tested code helps you to design better code.\n",
        "* Tests check your assumptions.\n",
        "* Tests help other people have confidence because tests need to be **automated, fast, reliable, informative and focused**.\n",
        "* Testing helps to write simpler code because is a way to write really good code.\n",
        "* Debugging is hard, testing is easy.\n"
      ],
      "metadata": {
        "id": "Wipjazn1gGxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## When and what to test?\n",
        "* When you change code, add a test. Don't try to write all the test at once.\n",
        "* Test the outcome, not the implementation\n",
        "* When you find a bug, add a test.\n",
        "* Help identify complexity. Write test as early as they can be valuable.\n",
        "* Don't test code that's already tested such as code from libraries already tested."
      ],
      "metadata": {
        "id": "0K6dAGM5mpxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Types of tests\n",
        "* **Unit tests**: Test one unit of code, a function that has no dependencies on other code you have written.\n",
        "* **Regression tests**: Tests to validate  a bug you fixed is not failing anymore.\n",
        "* **Integration tests**: Tests to validate components are working well together. For example, Integration testing with databases is one of the most vital, yet commonly overlooked part of any software development process\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ht47yvQGmgog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test isolation\n",
        "* Keep the test independent of each other. \n",
        "* Every test gets a new test object. \n",
        "* Tests can't affect each other and Failure doesn't stop next tests."
      ],
      "metadata": {
        "id": "Dhq2_fYNtxTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test-driven development?\n",
        "* Write failing test first, fix code until test pass.\n",
        "\n"
      ],
      "metadata": {
        "id": "jXVCaL-NmiYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LchSlTa0p1aB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## What does Testing mean for data scientist?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Testing for data science can be a little different because a lot of time deterministic answers may not exist for your problem necessaryly. You get probabilistic answers but the test pass because you write code in order to the tests pass.\n",
        "\n",
        "* Better ways to test could be test properties, not specific values, make assumptions about data shape and type, test probabilistically\n",
        " \n"
      ],
      "metadata": {
        "id": "DxpEu_MVmjc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>Frameworks for testing</font>\n",
        "\n",
        "If we want to be more robust we can use some frameworks for testing."
      ],
      "metadata": {
        "id": "Bn4EqLVNmmWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Unittest](https://docs.python.org/3/library/unittest.html)\n",
        "\n",
        "* The unittest unit testing framework was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages.\n",
        "* Instead of using **asset** we can use **asset helpers**.This methods print the value expected in the message when a test fails.\n",
        "\n",
        "| Lots of assert helpers | |\n",
        "| ------------------------| |\n",
        "| assertEqual(first,second) |assertNotEqual(first,second)\n",
        "| assertTrue(expr)|assertFalse(expr) |\n",
        "| assertIn(first,second) | assertNotIn(first,second)|\n",
        "| assertIn(first,second) | assertNotIn(first,second)|\n",
        "| assertIs(first,second) | assertIsNot(first,second)|\n",
        "| assertAlmostEqual(first,second) | assertGreater(first,second)|\n",
        "| assertLess(first,second) | assertRaises(exc_class,func,...)|\n",
        "| assertItemsEqual(seq1,seq2)| etc |\n"
      ],
      "metadata": {
        "id": "v-34zmV-qJZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n"
      ],
      "metadata": {
        "id": "XbHqze7xU6Je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# portfolio.py\n",
        "class Portofolio(object):\n",
        "  \"\"\" A simple stock portfolio\"\"\"\n",
        "  def __init__(self):\n",
        "    self.stocks=[]\n",
        "\n",
        "  def buy(self, name, shares,price):\n",
        "    \"\"\" Buy 'name': shares at price. \"\"\"\n",
        "    self.stocks.append([name,shares,price])\n",
        "\n",
        "  def cost(self):\n",
        "    \"\"\" What was the total cost of this portfolio \"\"\"\n",
        "    amt =0.0\n",
        "    for name, shares, price in self.stocks:\n",
        "      amt += shares* price\n",
        "    return amt"
      ],
      "metadata": {
        "id": "SXGwjFNyqj55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test_portfolio.py\n",
        "class PortfolioTest(unittest.TestCase):\n",
        "  def test_empty(self):\n",
        "    p=Portofolio()\n",
        "    # assert p.cost() == 0.0\n",
        "    self.assertEqual(p.cost() == 0.0)\n",
        "\n",
        "  def test_buy_one_stock(self):\n",
        "    p=Portofolio()\n",
        "    p.buy(\"IBM\", 100,176.48)\n",
        "    self.assertEqual(p.cost() == 17648.0)\n",
        "\n",
        "  def test_buy_two_stocks(self):\n",
        "    p=Portofolio()\n",
        "    p.buy(\"IBM\", 100,176.48)\n",
        "    p.buy(\"HPQ\", 100,36.15)\n",
        "    self.assertEqual(p.cost() == 21263.0)\n",
        "\n",
        "# Execute\n",
        "#$python -m unitttest test_portfolio"
      ],
      "metadata": {
        "id": "DtvOxlPuqnYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can implement your own base class."
      ],
      "metadata": {
        "id": "LH54RFc3wmta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_portfolio2.py\n",
        "class PortfolioTestCase(unittest.TestCase):\n",
        "  def assertCostEqual(self,p,cost):\n",
        "    self.assertEqual(p.cost() == cost)\n",
        "\n",
        "class PortfolioTest(PortfolioTestCase):\n",
        "  def test_empty(self):\n",
        "    p=Portofolio()\n",
        "    self.assertCostEqual(p,0.0)\n",
        "\n",
        "  def test_buy_one_stock(self):\n",
        "    p=Portofolio()\n",
        "    p.buy(\"IBM\", 100,176.48)\n",
        "    self.assertCostEqual(p, 17648.0)\n",
        "\n",
        "  def test_buy_two_stocks(self):\n",
        "    p=Portofolio()\n",
        "    p.buy(\"IBM\", 100,176.48)\n",
        "    p.buy(\"HPQ\", 100,36.15)\n",
        "    self.assertCostEqual(p,21263.0)\n"
      ],
      "metadata": {
        "id": "dLH784mcwV-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Py.test](https://docs.pytest.org/en/7.2.x/)\n",
        "\n",
        "In a project we see the **conftest.py** with fixtures and **pytest.ini** for configuration. Testing starts from given files/dirs or the current directory.Pytest walks over the filesytem and discover tests_*.py test files, test_ functions and Test clases. \n",
        "\n",
        "* Less boilerplate\n",
        "* Highly configurable \n",
        "* Fewer classes\n",
        "* Gets your testing quickly\n",
        "* Easy to interpret errors\n",
        "\n",
        "| Useful Options for Pytest | \n",
        "| ------------------------|\n",
        "| -s print all string output|\n",
        "| -v print names of individual test as the runall|\n",
        "| -x stop at first failure|\n",
        "| -k only run tests matching following keywords|\n",
        "| --pdb start Python debugger on errors|\n",
        "| --fixtures to see available fixtures|"
      ],
      "metadata": {
        "id": "iUPXPCRzEgOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to write a test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XoEB8AwqSfyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest"
      ],
      "metadata": {
        "id": "i9uYDL7wU8jN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unit code\n",
        "def mean(values):\n",
        "  \"\"\" Calculate the mean\"\"\"\n",
        "  return sum(values)/ len(values)\n",
        "\n",
        "# unit test implemented with pytest\n",
        "\n",
        "def test_mean():\n",
        "  assert(mean([1,2,3,4,5]) ==3)"
      ],
      "metadata": {
        "id": "XVd7Fn6YJlwI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit code\n",
        "def add_col(df,new_col_name, default_value):\n",
        "  \"\"\" Add a new column with a default value \"\"\"\n",
        "  df[new_col_name] = default_value\n",
        "  return df\n",
        "\n",
        "# unit test\n",
        "def test_add_col_passes():\n",
        "  # setup\n",
        "  df = pd.Dataframe({\n",
        "      'col_a': ['a','a','a'],\n",
        "      'col_b': ['b','b','b'],\n",
        "      'col_c': ['c','c','c'],\n",
        "  })\n",
        "  # call function\n",
        "  actual = add_col(df,'col_d','d')\n",
        "  \n",
        "  #set expectations\n",
        "  expected = pd.testing.assert_frame_equal(actual,expected)\n"
      ],
      "metadata": {
        "id": "OgvlOLExSOkX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unit code\n",
        "def divide(x,y):\n",
        "  return x/y\n",
        "\n",
        "# unit test for checking an exception is raised\n",
        "def test_raises():\n",
        "  with pytest.raises(ZeroDivisionError):\n",
        "    divide(3,0)"
      ],
      "metadata": {
        "id": "JgGNpEYeiWE2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to run tests\n",
        "`pytest name_file.py`"
      ],
      "metadata": {
        "id": "mVyFIj82isEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fixtures](https://docs.pytest.org/en/6.2.x/fixture.html)\n",
        "* Special functions pytest keeps track of to safely share resources and/or resource definitions.\n",
        "* A modular approach to setup and teardown methods.\n",
        "* We create a **conftest.py** file with fitxtures.\n",
        "* We can create **parametrize fixtures** and **compose fixtures**.\n",
        "* Fixtures are not imported are autodiscovered"
      ],
      "metadata": {
        "id": "iRQBpEaBT8fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#conftest.py\n",
        "\n",
        "@pytest.fixture() # decorators tells pytest this is a fixture\n",
        "def df():\n",
        "  return pd.Dataframe({\n",
        "      'col_a': ['a','a','a'],\n",
        "      'col_b': ['b','b','b'],\n",
        "      'col_c': ['c','c','c'],\n",
        "  })\n",
        "\n",
        "@pytest.fixture()\n",
        "def df_with_column_d():\n",
        "  return pd.Dataframe({\n",
        "      'col_a': ['a','a','a'],\n",
        "      'col_b': ['b','b','b'],\n",
        "      'col_c': ['c','c','c'],\n",
        "      'col_d': ['d','d','d'],\n",
        "  })\n",
        "\n",
        "@pytest.fixture()\n",
        "def somevalue(): \n",
        "  return 42"
      ],
      "metadata": {
        "id": "v7OcND69UUw2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's refactor the previous test with fixtures"
      ],
      "metadata": {
        "id": "kKEynxGPWFKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test with fixtures\n",
        "def test_add_col_passes_with_fixtures(df,df_with_column_d):\n",
        "  actual = add_col(df,'col_d','d')\n",
        "  expected = df_with_column_d\n",
        "  pd.testing.assert_frame_equal(actual,expected)\n"
      ],
      "metadata": {
        "id": "ua2yUQvOWF1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another example to see how we can use fixtures in tests"
      ],
      "metadata": {
        "id": "qDrSOfNNlczU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pytest.fixture(scope='function') # Fixture function\n",
        "def fix(): \n",
        "  time.sleep(1)\n",
        "  return 1\n",
        "\n",
        "# Test\n",
        "def test_func(fix):  # the parameter is the name of the fixture\n",
        "  assert fix == 1"
      ],
      "metadata": {
        "id": "dTjAu_DckQ4n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Compose Fixtures*\n",
        "Let's create a fixture that depends on the first"
      ],
      "metadata": {
        "id": "QWUc3s7NYk1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope='session') # Fixture session\n",
        "def spark(request):\n",
        "  spark = SparkSession.builder \\\n",
        "    .appName(\"Word Count\") \\\n",
        "    .master(\"local[2]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define a new fixture that depends on the first\n",
        "@pytest.fixture()  \n",
        "def spark_df(spark):\n",
        "  return spark.createDataFrame(\n",
        "      [\n",
        "          ('a','b','c','d'),\n",
        "          ('a','b','c','d'),\n",
        "      ],\n",
        "      ['col_a','col_b','col_c','col_d']\n",
        "  )"
      ],
      "metadata": {
        "id": "7RMJgivCWk7l"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Parametrized Fixtures*"
      ],
      "metadata": {
        "id": "lU7nF414pHiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pytest.fixture(params=[10,20])\n",
        "def answer1(request):\n",
        "  return 5 * request.param\n",
        "\n",
        "@pytest.fixture(params=[2,4])\n",
        "def answer2(answer1,request):\n",
        "  return answer1 * request.param\n",
        "\n",
        "# Python runs 4 test with all of the combinations [2-10],[2-20],[4-10],[4-20]\n",
        "def test_answer(answer2):\n",
        "  print(answer2)"
      ],
      "metadata": {
        "id": "MLoSsAHlXlZJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fixture to provide a text file to tests"
      ],
      "metadata": {
        "id": "x1qHqX6hnSEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "@pytest.fixture\n",
        "def input_file(tmp_path):\n",
        "  path = tmp_path  # ex: \"input.txt\"\n",
        "  path.write_text(\"Hello world\")\n",
        "  return path\n",
        "\n",
        "def test_things(input_file):\n",
        "  assert False, str(input_file)"
      ],
      "metadata": {
        "id": "-AwIlfpInWqc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Fixture for databases](https://medium.com/@geoffreykoh/fun-with-fixtures-for-database-applications-8253eaf1a6d)"
      ],
      "metadata": {
        "id": "diDNBgMzqn5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you want to prepare the test environment before any test is run, a fixture can tak autouse=True. The test db will be created ahead of the first test.  "
      ],
      "metadata": {
        "id": "1z1Kw1uIoQvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pytest.fixture(scope='session', autouse=True)\n",
        "def setup_database():\n",
        "    \"\"\" Fixture to set up the in-memory database with test data \"\"\"\n",
        "    conn = sqlite3.connect(':memory:')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "\t    CREATE TABLE stocks\n",
        "        (date text, trans text, symbol text, qty real, price real)''')\n",
        "    sample_data = [\n",
        "        ('2020-01-01', 'BUY', 'IBM', 1000, 45.0),\n",
        "        ('2020-01-01', 'SELL', 'GOOG', 40, 123.0),\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO stocks VALUES(?, ?, ?, ?, ?)', sample_data)\n",
        "    yield conn\n",
        "\n",
        "# Test to make sure that there are 2 items in the database\n",
        "def test_connection(setup_database):\n",
        "    cursor = setup_database\n",
        "    assert len(list(cursor.execute('SELECT * FROM stocks'))) == 2"
      ],
      "metadata": {
        "id": "xiieoixCn2K0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Mocks\n",
        "Replacing and object with a **mock** allows you to avoid external dependencies. We can mock:\n",
        "* Data reads or writes\n",
        "* API calls\n",
        "* External functions you don't want to test\n",
        "\n"
      ],
      "metadata": {
        "id": "mKBQuCBMm0Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "\n",
        "@pytest.fixture(scope='function')\n",
        "def genetate_features():\n",
        "\n",
        "    engine = create_engine('fake_connection_string')\n",
        "    df = pd.read_sql('SELECT col1, col2 FROM data_table;', con=engine)\n",
        "    # ... processing on df ...\n",
        "    return features\n",
        "\n",
        "@mock.path()\n",
        "def test_generate_features(read_sql_mock,engine_mock, db_creds,df):\n",
        "  read_sql_mock.return_value=df\n",
        "  actual_features_=\n"
      ],
      "metadata": {
        "id": "gj8L89ElrLl6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Engarde](https://github.com/engarde-dev/engarde)\n",
        "* For \"defensive\" data analysis when data are messy. \n",
        "* Great for ETL on changing data."
      ],
      "metadata": {
        "id": "54mAaTtSOUdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from engarde.decorators import none_missing,unique_index, is_shape\n",
        "\n",
        "# Test\n",
        "@is_shape((3, 2))\n",
        "@none_missing()\n",
        "def test_nan_and_shape(df):\n",
        "  return df"
      ],
      "metadata": {
        "id": "vzCd_45qIkkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example OK: The test should pass because there isn't any nan value\n",
        "d = {'name': ['Mary', 'Paul','James'], 'age': [18, 19,20]}\n",
        "df_OK = pd.DataFrame(data=d)\n",
        "\n",
        "test_nan_and_shape(df_OK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VuHDA-_BM-vJ",
        "outputId": "50fb808b-17d5-4242-f6fb-3d1896e386e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    name  age\n",
              "0   Mary   18\n",
              "1   Paul   19\n",
              "2  James   20"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75ce52ff-2160-40a5-ae49-161c8e45f94c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mary</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paul</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75ce52ff-2160-40a5-ae49-161c8e45f94c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75ce52ff-2160-40a5-ae49-161c8e45f94c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75ce52ff-2160-40a5-ae49-161c8e45f94c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example KO: The test should fail because there is a nan value\n",
        "d = {'name': ['Mary', 'Paul','James'], 'age': [18, 19,np.nan]}\n",
        "df_KO = pd.DataFrame(data=d)\n",
        "\n",
        "test_nan_and_shape(df_KO)"
      ],
      "metadata": {
        "id": "QIFYR0FCM91N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Bulwark](https://github.com/zaxr/bulwark)\n",
        "\n",
        "Bulwark is a package for convenient property-based testing of pandas dataframes.  Bulwark's goal is to let you check that your data meets your assumptions of what it should look like at any (and every) step in your code, without making you work too hard.\n"
      ],
      "metadata": {
        "id": "jCSopOyUc25r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bulwark.checks as ck\n",
        "import bulwark.decorators as dc\n",
        "\n",
        "def len_longer_than(df, l):\n",
        "  if len(df) <= l:\n",
        "    raise AssertionError(\"df is not as long as expected.\")\n",
        "  return df\n",
        "\n",
        "@dc.CustomCheck(len_longer_than, 10, enabled=False)\n",
        "def append_a_df(df, df2):\n",
        "  return df.append(df2, ignore_index=True)\n",
        "\n",
        "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
        "df2 = pd.DataFrame({\"a\": [1, np.nan, 3, 4], \"b\": [4, 5, 6, 7]})\n",
        "\n",
        "append_a_df(df, df2)  # doesn't fail because the check is disabled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "oxWaH5GCds6q",
        "outputId": "d8aa6c92-4ef2-4e28-cf4f-79ae51e29695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a  b\n",
              "0  1.0  4\n",
              "1  2.0  5\n",
              "2  3.0  6\n",
              "3  1.0  4\n",
              "4  NaN  5\n",
              "5  3.0  6\n",
              "6  4.0  7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-859b3d0d-4d39-472f-86d6-630a69f59eff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-859b3d0d-4d39-472f-86d6-630a69f59eff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-859b3d0d-4d39-472f-86d6-630a69f59eff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-859b3d0d-4d39-472f-86d6-630a69f59eff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Hypothesis](https://hypothesis.readthedocs.io/en/latest/)\n",
        "* Property-base testing inspired by Haskell's Quickcheck.\n",
        "* We generate data randomly according to some specs.\n",
        "* Ideal for code that will be accepting input from the wild.\n",
        "* Work with existing testing frameworks like pytest \n",
        "* Work with Faker"
      ],
      "metadata": {
        "id": "1j5qz54SQ3lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hypothesis import given\n",
        "import hypothesis.strategies as st\n",
        "\n",
        "@given(st.integers(), st.integers())\n",
        "def test_ints_are_commutative(x, y):\n",
        "    assert x + y == y + x\n",
        "\n",
        "test_ints_are_commutative()"
      ],
      "metadata": {
        "id": "0ZtD4tJ6V1ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hypothesis import given\n",
        "import hypothesis.strategies as st\n",
        "\n",
        "@given(st.lists(st.integers()))\n",
        "def test_mean(values):\n",
        "  print(values)\n",
        "  assert mean(values) == sum(values)/len(values)\n",
        "\n",
        "# The test mean fails because the function mean hasn't added the case for empty values.\n",
        "test_mean()"
      ],
      "metadata": {
        "id": "VYc3zN_IR9Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Feature Forge](https://github.com/machinalis/featureforge)\n",
        "\n",
        "This library provides a set of tools that can be useful in many machine learning applications (classification, clustering, regression, etc.), and particularly helpful if you use scikit-learn.\n",
        "\n",
        "* Defining and documenting features\n",
        "* Testing your features against specified cases and against randomly generated cases (stress-testing). This helps you making your application more robust against invalid/misformatted input data. This also helps you checking that low-relevance results when doing feature analysis is actually because the feature is bad, and not because there's a slight bug in your feature code.\n",
        "* Evaluating your features on a data set, producing a feature evaluation matrix. The evaluator has a robust mode that allows you some tolerance both for invalid data and buggy features.\n",
        "* Experimentation: running, registering, classifying and reproducing experiments for determining best settings for your problems."
      ],
      "metadata": {
        "id": "qzUnrv4DXLjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>Cool talks </font>\t😄\n",
        "Most examples are explained in these awesome talks. \n",
        "* [PyCon Ned Batchelder: Getting started Testing](https://www.youtube.com/watch?v=FxSsnHeWQBY)\n",
        "*  [PyData Hanna Torrence: Unit testing for Datascientis](https://www.youtube.com/watch?v=Da-FL_1i6ps)\n",
        "* [PyData Trey Causey: Testing for Data Scientists](https://www.youtube.com/watch?v=GEqM9uJi64Q)\n",
        "* [PyConDE Floriah Bruhin: Pytest - simple, rapid and fun testing with Python](https://www.youtube.com/watch?v=CMuSn9cofbI)\n"
      ],
      "metadata": {
        "id": "7Nd4h1UJTRhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# More Resources\n",
        "* [This pytest plugin provides a mocker fixture](https://pytest-mock.readthedocs.io/en/latest/)\n",
        "* [PyTest Talks and Tutorials](https://docs.pytest.org/en/6.2.x/talks.html?highlight=mock)\n",
        "* [PyData Github](https://github.com/PyData)\n",
        "* [PyCon Github](https://github.com/PyCon)\n",
        "* [Towards Data Science: PyTest with mocking and fixtures](https://towardsdatascience.com/pytest-with-marking-mocking-and-fixtures-in-10-minutes-678d7ccd2f70)\n",
        "\n",
        "\n",
        "* https://www.inspiredpython.com/course/testing-with-hypothesis/testing-your-python-code-with-hypothesis\n",
        "* https://medium.com/@rinu.gour123/unit-testing-with-python-unittest-ad045671010\n",
        "* https://towardsdatascience.com/pytest-with-marking-mocking-and-fixtures-in-10-minutes-678d7ccd2f70\n",
        "* https://www.softwaretestinghelp.com/python-testing-frameworks/\n",
        "* https://medium.com/@arnabroyy/best-python-testing-frameworks-bb7ab1b3d366\n",
        "* https://mlinproduction.com/testing-machine-learning-models-deployment-series-07/\n",
        "\n",
        "* [How and why to test Data Pipelines](https://www.youtube.com/watch?v=JYAcKSkCl8w)"
      ],
      "metadata": {
        "id": "-Fi7_6sSiLxh"
      }
    }
  ]
}